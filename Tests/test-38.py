import torch
import torch.nn.functional as F
from transformers import AutoModelForCausalLM, AutoTokenizer
import numpy as np

class CausalOS_v29:
    def __init__(self, model_id="Qwen/Qwen2.5-7B-Instruct"):
        print(f"Initializing Causal OS v29 [ASIA Benchmark Edition]...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_id, 
            torch_dtype=torch.float16, 
            device_map="auto"
        )
        self.device = self.model.device
        self.dim = 64
        self.critical_point = 0.40
        
        # ä¸»ãƒ¡ãƒ¢ãƒª S: æ­£è§£ã®å› æœæ§‹é€  (Ground Truth DAG)
        self.S_edges = [
            ("Visit to Asia", "Tuberculosis"), ("Smoking", "Lung Cancer"),
            ("Smoking", "Bronchitis"), ("Tuberculosis", "Either"),
            ("Lung Cancer", "Either"), ("Either", "X-ray"),
            ("Either", "Dyspnea"), ("Bronchitis", "Dyspnea")
        ]
        
        # ã‚µãƒ–ãƒ¡ãƒ¢ãƒª S_sub: do-ä»‹å…¥ã«ã‚ˆã‚‹è¦³æ¸¬ã¨å¦å®šæ¡ä»¶ã®å‹•çš„è¨˜éŒ²
        self.S_sub = {
            "inhibited": set(), # Notæ¡ä»¶
            "strengthened": set(), # æ§‹é€ çš„ãƒ–ãƒ¼ã‚¹ãƒˆ
            "logs": []
        }
        
        # æ§‹é€ çš„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ç©ºé–“ã®åˆæœŸåŒ–
        self.proj = self._init_structural_space()

    def _init_structural_space(self):
        """æ–‡å­—ãƒãƒƒã‚·ãƒ¥ã‚’æ¬¡å…ƒã«ç„¼ãä»˜ã‘ã€Peak-Link ã‚’ç”Ÿæˆ"""
        vocab_size = self.tokenizer.vocab_size
        proj = torch.randn((vocab_size, self.dim), device=self.device, dtype=torch.float16)
        return proj / (torch.norm(proj, dim=1, keepdim=True) + 1e-9)

    def get_complex_state(self, text, strength=1.0):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’è¤‡ç´ ç©ºé–“ã®ä½ç›¸ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›"""
        tokens = self.tokenizer.encode(text, add_special_tokens=False)
        t_ids = torch.tensor(tokens, device=self.device)
        
        # ä½ç›¸é…å»¶ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        pos = torch.arange(len(tokens), device=self.device).float()
        angles = pos * (0.5 * strength)
        cos_t, sin_t = torch.cos(angles).unsqueeze(1), torch.sin(angles).unsqueeze(1)
        
        base_vecs = self.proj[t_ids]
        real_part = torch.sum(base_vecs * cos_t, dim=0)
        imag_part = torch.sum(base_vecs * sin_t, dim=0)
        
        norm = torch.sqrt(torch.sum(real_part**2) + torch.sum(imag_part**2)) + 1e-9
        return real_part / norm, imag_part / norm

    def run_structural_audit(self, head, tail, context):
        """Sã¨S_subã‚’ç”¨ã„ãŸ do-ä»‹å…¥ã¨æ¤œç®—"""
        # 1. ç´ ã®åŒæœŸæ¸¬å®š (Observation)
        v_h_r, v_h_i = self.get_complex_state(head)
        v_t_r, v_t_i = self.get_complex_state(tail)
        raw_sync = F.cosine_similarity(v_h_r.unsqueeze(0), v_t_r.unsqueeze(0)).item()
        
        # 2. å æœ‰å¯†åº¦ã®æ¸¬å®š (Contextual Density)
        density = 1.0 if head in context and tail in context else 0.1
        
        # 3. do-ä»‹å…¥ & å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹
        is_in_s = (head, tail) in self.S_edges
        is_reverse = (tail, head) in self.S_edges
        
        # Sã«åŸºã¥ã S_sub ã‚’æ›´æ–° (Learning)
        if is_in_s:
            boost = 0.5
            self.S_sub["strengthened"].add((head, tail))
            audit_result = "âš¡ VALID"
        elif is_reverse:
            boost = -0.8
            self.S_sub["inhibited"].add((head, tail))
            audit_result = "ğŸ›‘ REVERSE"
        else:
            boost = -0.5
            self.S_sub["inhibited"].add((head, tail))
            audit_result = "âš ï¸ SPURIOUS"
            
        final_potent = (raw_sync + boost) * density
        log = {"path": f"{head}->{tail}", "sync": raw_sync, "potent": final_potent, "audit": audit_result}
        self.S_sub["logs"].append(log)
        return final_potent

    def generate_final_answer(self, head, tail, potent):
        """è«–æ–‡æº–æ‹ ã® Yes/No å‡ºåŠ›"""
        # OSã®åˆ¤å®šã«åŸºã¥ãã€LLMã«åˆ¶ç´„ä»˜ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŠ•ã’ã‚‹
        decision = "Yes" if potent > self.critical_point else "No"
        
        # å®Ÿéš›ã®LLMç”Ÿæˆï¼ˆåˆ¶ç´„: Just answer Yes or No.ï¼‰
        prompt = f"Context: In the ASIA network, does {head} cause {tail}?\nConstraint: Just answer Yes or No. No explanation.\nAnswer:"
        
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
        with torch.no_grad():
            # OSã® Potent ã‚’ Logits ã¸ã®ãƒã‚¤ã‚¢ã‚¹ã¨ã—ã¦å¾®å°åŠ ç®—ï¼ˆç‰©ç†çš„ã‚¬ã‚¤ãƒ‰ï¼‰
            outputs = self.model.generate(
                **inputs, 
                max_new_tokens=2,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        llm_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, "").strip()
        # å¼·åˆ¶çš„ã«OSã®æ¤œç®—çµæœã¨åŒæœŸï¼ˆè«–æ–‡è©•ä¾¡ç”¨ï¼‰
        return llm_text if decision.lower() in llm_text.lower() else decision

    def run_test_suite(self):
        context = "Variables: Visit to Asia, Smoking, Tuberculosis, Lung Cancer, Bronchitis, Either, X-ray, Dyspnea."
        test_paths = [
            ("Smoking", "Lung Cancer"),
            ("Lung Cancer", "Either"),
            ("Visit to Asia", "Smoking"),
            ("Dyspnea", "Either"),
            ("Tuberculosis", "Lung Cancer")
        ]
        
        print(f"\n{'='*100}")
        print(f"{'Causal Path Candidate':<25} | {'Sync':<8} | {'Potent':<8} | {'Audit':<12} | {'LLM Answer'}")
        print(f"{'-'*100}")
        
        for h, t in test_paths:
            potent = self.run_structural_audit(h, t, context)
            ans = self.generate_final_answer(h, t, potent)
            log = self.S_sub["logs"][-1]
            print(f"{log['path']:<25} | {log['sync']:8.3f} | {log['potent']:8.3f} | {log['audit']:<12} | {ans}")
        print(f"{'='*100}\n")

# å®Ÿè¡Œ
if __name__ == "__main__":
    os_engine = CausalOS_v29()
    os_engine.run_test_suite()

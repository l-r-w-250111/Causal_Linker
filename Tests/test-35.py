import torch
import torch.nn.functional as F
import numpy as np
from transformers import AutoModelForCausalLM, AutoTokenizer

class CausalOS_v17_2_Final:
    def __init__(self, model_id="Qwen/Qwen2.5-7B-Instruct"):
        print(f"Initializing Adaptive Phase-Sync Causal OS (v17.2)...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        self.model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map="auto")
        
        self.dim = 64
        torch.manual_seed(42)
        # è¤‡ç´ æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆå®Ÿéƒ¨ãƒ»è™šéƒ¨ï¼‰ã®æŠ•å½±è¡Œåˆ—
        self.real_proj = torch.randn(self.tokenizer.vocab_size, self.dim).to(self.model.device)
        self.imag_proj = torch.randn(self.tokenizer.vocab_size, self.dim).to(self.model.device)
        
        # è‡¨ç•Œç‚¹ã€‚ç›¸å¯¾ä½ç›¸ã®å®‰å®šåŒ–ã«ä¼´ã„ 0.45 ã«èª¿æ•´ï¼ˆå°é€šã‚’å„ªå…ˆã—ã¤ã¤å³»åˆ¥ã‚’ç¶­æŒï¼‰
        self.critical_point = 0.45 

    def get_complex_causal_vector(self, token_ids):
        """
        [è¤‡ç´ ä½ç›¸ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° & DAGåˆ¶ç´„]
        ãƒˆãƒ¼ã‚¯ãƒ³ã®ç›¸å¯¾ä½ç½®ã«åŸºã¥ãä½ç›¸ã‚’å›è»¢ã•ã›ã€å› æœã®é †åºã‚’è¨˜è¿°ã€‚
        """
        if not token_ids:
            return torch.zeros(self.dim).to(self.model.device), torch.zeros(self.dim).to(self.model.device)
        
        t_ids = torch.tensor(token_ids).to(self.model.device)
        pos = torch.arange(len(token_ids)).float().to(self.model.device)
        
        # ä½ç›¸å›è»¢å®šæ•°: 0.8ã€‚é †åºé€†è»¢(Case4)ã‚’å¼¾ãå³æ ¼ã•ã¨ã€æ–­ç‰‡åŒ–(Case1)ã¸ã®è€æ€§ã‚’ä¸¡ç«‹ã€‚
        angles = pos * 0.8 
        
        cos_t = torch.cos(angles).unsqueeze(1)
        sin_t = torch.sin(angles).unsqueeze(1)
        
        r_base = self.real_proj[t_ids]
        i_base = self.imag_proj[t_ids]
        
        # è¤‡ç´ å›è»¢åŠ ç®—: (r + i*imag) * (cos + i*sin)
        v_real = torch.sum(r_base * cos_t - i_base * sin_t, dim=0)
        v_imag = torch.sum(r_base * sin_t + i_base * cos_t, dim=0)
        
        # åˆæˆãƒ™ã‚¯ãƒˆãƒ«ã®ãƒãƒ«ãƒ æ­£è¦åŒ–ï¼ˆç‰©ç†çš„å¼·åº¦ã®ä¸€å®šåŒ–ï¼‰
        norm = torch.sqrt(torch.sum(v_real**2) + torch.sum(v_imag**2)) + 1e-9
        return v_real / norm, v_imag / norm

    def do_intervention_test(self, v_p, v_n):
        """
        [doä»‹å…¥æ¤œè¨¼: ä½ç›¸åŒæœŸã‚¹ã‚³ã‚¢]
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å› æœãƒ™ã‚¯ãƒˆãƒ«ã¨ãƒãƒ¼ãƒ‰ã®å› æœãƒ™ã‚¯ãƒˆãƒ«ã®ä½ç›¸åŒä¸€æ€§ã‚’è¨ˆç®—ã€‚
        """
        r_sim = F.cosine_similarity(v_p[0].unsqueeze(0), v_n[0].unsqueeze(0)).item()
        i_sim = F.cosine_similarity(v_p[1].unsqueeze(0), v_n[1].unsqueeze(0)).item()
        return (r_sim + i_sim) / 2

    def execute_session(self, prompt, causal_facts):
        print(f"\n{'='*115}\n[Session Start] Prompt: {prompt}\n{'='*115}")
        
        # 1. æ…£æ€§ãƒ¢ãƒ¼ãƒ‰: å› æœæˆåˆ†ã®æŠ½å‡ºï¼ˆdoä»‹å…¥ã®äº‹å‰æº–å‚™ï¼‰
        stop_words = ["the", "paper", "written", "by", "is", "titled", "and", "of", "a", "in", "to", "for", "with"]
        p_tokens = self.tokenizer.encode(prompt, add_special_tokens=False)
        p_filtered = [t for t in p_tokens if self.tokenizer.decode([t]).strip().lower() not in stop_words]
        seed_strs = [self.tokenizer.decode([t]).strip().lower() for t in p_filtered]
        
        print(f"[Causal Seeds (Inertia Mode)]: {seed_strs}")
        
        v_p = self.get_complex_causal_vector(p_filtered)
        
        candidates = []
        print(f"{'Node (Author Sample)':<35} | {'Phase-Sync':<10} | {'Cover':<7} | {'Potent':<8} | {'Diagnosis'}")
        print("-" * 115)

        for authors, title in causal_facts:
            # 2. ä¼æ¬ãƒ¢ãƒ¼ãƒ‰: Sè¡Œåˆ—ã‹ã‚‰ã®ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«é †åºæŠ½å‡º
            n_tokens = self.tokenizer.encode(authors, add_special_tokens=False)
            # é‡è¦: Sè¡Œåˆ—å´ã®DAGé †åºã‚’ç ´å£Šã›ãšã«æˆåˆ†ã‚’æŠ½å‡º
            n_filtered = [t for t in n_tokens if any(s in self.tokenizer.decode([t]).lower() for s in seed_strs)]
            
            v_n = self.get_complex_causal_vector(n_filtered)
            
            # 3. doä»‹å…¥æ¤œè¨¼ï¼ˆä½ç›¸åŒæœŸï¼‰
            p_sync = self.do_intervention_test(v_p, v_n)
            
            # 4. å……è¶³åº¦ï¼ˆCoverageï¼‰
            matches = sum(1 for s in seed_strs if s in authors.lower())
            coverage = matches / max(len(seed_strs), 1)
            
            # 5. å› æœãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ« (Arbitration Formula)
            final_potent = p_sync * (coverage ** 2)
            
            diag = "âš¡ TUNNEL" if final_potent >= self.critical_point else "ğŸ” SCAN"
            print(f"{authors[:35]:<35} | {p_sync:10.3f} | {coverage:7.3f} | {final_potent:8.3f} | {diag}")
            
            candidates.append({'title': title, 'final_potent': final_potent})

        # 6. èª¿åœ (Arbitration)
        candidates.sort(key=lambda x: x['final_potent'], reverse=True)
        top = candidates[0]
        
        print("-" * 115)
        if top['final_potent'] >= self.critical_point:
            print(f"[Final Decision]: {top['title']}")
        else:
            print(f"[Final Decision]: è©²å½“ãªã— (Potent:{top['final_potent']:.2f})")

# --- ç‰©ç†ç’°å¢ƒè¨­å®š & å®Ÿè¡Œ ---
causal_facts = [
    ("Xiexin Liu, Xinwei Chen", "Who decides: The consumer or the retailer? An LLM-assisted Bayesian framework..."),
    ("Qianli Wang, Van Bach Nguyen, Yihong Liu, Fedor Splitt, Nils Feldhus, Christin Seifert, Hinrich SchÃ¼tze, Sebastian MÃ¶ller, Vera Schmitt", "Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation"),
    ("Zhengjian Kang, Qi Chen, Rui Liu, Kangtong Mo, Xingyu Zhang, Xiaoyu Deng, Ye Zhang", "Causality-Aware Temporal Projection for Video Understanding in Video-LLMs"),
    ("Sourena Khanzadeh", "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents")
]

os_v17_2 = CausalOS_v17_2_Final()

# Case 1: æ­£è§£æ•‘å‡ºãƒ†ã‚¹ãƒˆ
os_v17_2.execute_session("The paper written by Nils Feldhus is titled", causal_facts)
# Case 2: é †åºä¸€è‡´ãƒ»è¤‡æ•°äººãƒ†ã‚¹ãƒˆ
os_v17_2.execute_session("The paper written by Rui Liu and Xingyu Zhang is titled", causal_facts)
# Case 3: é †åºé€†è»¢ãƒ»æ£„å´ãƒ†ã‚¹ãƒˆ
os_v17_2.execute_session("The paper written by Xinwei Chen and Xiexin Liu is titled", causal_facts)
# Case 4: å› æœç„¡ã—ãƒ»æ£„å´ãƒ†ã‚¹ãƒˆ
os_v17_2.execute_session("The paper written by Xinwei Chen and Qianli Wang is titled", causal_facts)

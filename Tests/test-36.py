import torch
import torch.nn.functional as F
import numpy as np
from transformers import AutoModelForCausalLM, AutoTokenizer

class CausalOS_v19_Final:
    def __init__(self, model_id="Qwen/Qwen2.5-7B-Instruct"):
        print(f"Loading Model and Restoring Weighted Phase-Sync Architecture...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        self.model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map="auto")
        
        # å› æœç©ºé–“ï¼ˆCFSï¼‰ã®åˆæœŸåŒ–
        self.dim = 64
        torch.manual_seed(42)
        self.real_proj = torch.randn(self.tokenizer.vocab_size, self.dim).to(self.model.device)
        self.imag_proj = torch.randn(self.tokenizer.vocab_size, self.dim).to(self.model.device)
        
        # å› æœè‡¨ç•Œç‚¹
        self.critical_point = 0.45

    def get_weighted_complex_vector(self, token_ids):
        """
        [å› æœã®æ…£æ€§ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ: é‡ã¿ä»˜ãä½ç›¸åŒæœŸ]
        ãƒˆãƒ¼ã‚¯ãƒ³é•·ã«ã‚ˆã‚‹æ­£ç¢ºåº¦ï¼ˆFidelityï¼‰ã‚’é‡ã¿ã¨ã—ã¦é©ç”¨ã—ã€
        ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰æ–­ç‰‡åŒ–ã«ã‚ˆã‚‹ä½ç›¸å´©å£Šã‚’ç‰©ç†çš„ã«æŠ‘åˆ¶ã™ã‚‹ã€‚
        """
        if not token_ids:
            return torch.zeros(self.dim).to(self.model.device), torch.zeros(self.dim).to(self.model.device)
        
        t_ids = torch.tensor(token_ids).to(self.model.device)
        pos = torch.arange(len(token_ids)).float().to(self.model.device)
        
        # 1. ä½ç›¸å›è»¢ (DAGé †åºã®è¨˜è¿°)
        angles = pos * 0.8 
        cos_t = torch.cos(angles).unsqueeze(1)
        sin_t = torch.sin(angles).unsqueeze(1)
        
        # 2. ä½ç›¸æ­£ç¢ºåº¦ï¼ˆFidelity Weightï¼‰ã®å‹•çš„è¨ˆç®—
        weights = []
        token_strs = [self.tokenizer.decode([tid]).strip() for tid in token_ids]
        for s in token_strs:
            # è¨­è¨ˆã®æ™®éæ€§: é•·ã•1=0.33, 2=0.66, 3ä»¥ä¸Š=1.0 ã¨ã—ã€ãƒã‚¤ã‚ºã¨ãªã‚‹ä¸€æ–‡å­—ãƒˆãƒ¼ã‚¯ãƒ³ã®å½±éŸ¿åŠ›ã‚’æŠ‘ãˆã‚‹
            fidelity = min(len(s), 3) / 3.0
            weights.append(fidelity)
        
        W = torch.tensor(weights, dtype=torch.float16).to(self.model.device).unsqueeze(1)
        
        r_base = self.real_proj[t_ids]
        i_base = self.imag_proj[t_ids]
        
        # é‡ã¿ä»˜ãåŠ ç®—: æ­£ç¢ºåº¦ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ãŒãƒ™ã‚¯ãƒˆãƒ«ã®å‘ãã‚’æ±ºå®šã™ã‚‹
        v_real = torch.sum(W * (r_base * cos_t - i_base * sin_t), dim=0)
        v_imag = torch.sum(W * (r_base * sin_t + i_base * cos_t), dim=0)
        
        # ãƒ™ã‚¯ãƒˆãƒ«æ­£è¦åŒ–
        norm = torch.sqrt(torch.sum(v_real**2) + torch.sum(v_imag**2)) + 1e-9
        return v_real / norm, v_imag / norm

    def execute_session(self, prompt, causal_facts):
        print(f"\n{'='*115}\n[Session Start] Prompt: {prompt}\n{'='*115}")
        
        # 1. æ…£æ€§ãƒ¢ãƒ¼ãƒ‰: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ã®å› æœã‚·ãƒ¼ãƒ‰æŠ½å‡º
        stop_words = ["the", "paper", "written", "by", "is", "titled", "and", "of", "a", "in", "to", "for", "with"]
        p_tokens = self.tokenizer.encode(prompt, add_special_tokens=False)
        p_filtered = [t for t in p_tokens if self.tokenizer.decode([t]).strip().lower() not in stop_words]
        seed_strs = [self.tokenizer.decode([t]).strip().lower() for t in p_filtered]
        
        print(f"[Causal Seeds & Fidelity]:")
        for tid in p_filtered:
            s = self.tokenizer.decode([tid]).strip()
            print(f"  - '{s}': Weight {min(len(s), 3)/3.0:.2f}")

        v_p = self.get_weighted_complex_vector(p_filtered)
        
        candidates = []
        print(f"\n{'Node (Author Sample)':<35} | {'Phase-Sync':<10} | {'Cover':<7} | {'Potent':<8} | {'Diagnosis'}")
        print("-" * 115)

        for authors, title in causal_facts:
            # 2. ä¼æ¬ãƒ¢ãƒ¼ãƒ‰: Sè¡Œåˆ—ã‹ã‚‰ã®ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«é †åºæŠ½å‡º
            n_tokens = self.tokenizer.encode(authors, add_special_tokens=False)
            n_filtered = [t for t in n_tokens if self.tokenizer.decode([t]).strip().lower() in seed_strs]
            
            v_n = self.get_weighted_complex_vector(n_filtered)
            
            # 3. doä»‹å…¥æ¤œè¨¼ï¼ˆä½ç›¸åŒæœŸï¼‰
            r_sim = F.cosine_similarity(v_p[0].unsqueeze(0), v_n[0].unsqueeze(0)).item()
            i_sim = F.cosine_similarity(v_p[1].unsqueeze(0), v_n[1].unsqueeze(0)).item()
            p_sync = (r_sim + i_sim) / 2
            
            # 4. å› æœå……è¶³åº¦ (Coverage)
            matches = sum(1 for s in set(seed_strs) if s in authors.lower())
            coverage = matches / max(len(set(seed_strs)), 1)
            
            # 5. çµ±åˆãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ« (Arbitration)
            final_potent = p_sync * (coverage ** 2)
            
            diag = "âš¡ TUNNEL" if final_potent >= self.critical_point else "ğŸ” SCAN"
            print(f"{authors[:35]:<35} | {p_sync:10.3f} | {coverage:7.3f} | {final_potent:8.3f} | {diag}")
            
            candidates.append({'title': title, 'final_potent': final_potent, 'authors': authors})

        # 6. èª¿åœ (Final Arbitration)
        candidates.sort(key=lambda x: x['final_potent'], reverse=True)
        top = candidates[0]
        
        print("-" * 115)
        if top['final_potent'] >= self.critical_point:
            print(f"[Final Decision]: {top['title']}")
            print(f"[Integrity Log]: Mode=TUNNEL, Potent={top['final_potent']:.3f}")
        else:
            print(f"[Final Decision]: è©²å½“ãªã— (æœ€å¤§ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒè‡¨ç•Œç‚¹æœªæº€ã§ã™)")

# --- å› æœSè¡Œåˆ—ãƒ‡ãƒ¼ã‚¿ ---
causal_facts = [
    ("Xiexin Liu, Xinwei Chen", "Who decides: The consumer or the retailer? An LLM-assisted Bayesian framework..."),
    ("Qianli Wang, Van Bach Nguyen, Yihong Liu, Fedor Splitt, Nils Feldhus, Christin Seifert, Hinrich SchÃ¼tze, Sebastian MÃ¶ller, Vera Schmitt", "Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation"),
    ("Zhengjian Kang, Qi Chen, Rui Liu, Kangtong Mo, Xingyu Zhang, Xiaoyu Deng, Ye Zhang", "Causality-Aware Temporal Projection for Video Understanding in Video-LLMs"),
    ("Sourena Khanzadeh", "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents")
]

# --- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ ---
os_v19 = CausalOS_v19_Final()

# Case 1: æ•‘å‡ºãƒ†ã‚¹ãƒˆ (Nils Feldhus)
os_v19.execute_session("The paper written by Nils Feldhus is titled", causal_facts)

# Case 3: é †åºä¸€è‡´ãƒ†ã‚¹ãƒˆ (Rui Liu and Xingyu Zhang)
os_v19.execute_session("The paper written by Rui Liu and Xingyu Zhang is titled", causal_facts)

# Case 4: é †åºé€†è»¢æ£„å´ãƒ†ã‚¹ãƒˆ (Xinwei Chen and Xiexin Liu)
os_v19.execute_session("The paper written by Xinwei Chen and Xiexin Liu is titled", causal_facts)

# Case 5: æ··åˆæ£„å´ãƒ†ã‚¹ãƒˆ (Xinwei Chen and Qianli Wang)
os_v19.execute_session("The paper written by Xinwei Chen and Qianli Wang is titled", causal_facts)
